{
    "experiment": {
       "id": "exp1.0-ACD-with-prompt",
       "description": "ACD on weibo-Convid19 dataset",
       "do_training": true,
       "output_dir": "results",
       "taskname": "ACD_Prefix",
       "input_ckpt_path": "/root/02-ACD-Prompt_v1.0/ckpt/",
       "output_ckpt": "/root/02-ACD-Prompt_v1.0/ckpt/output_ckpt",
       "num_epoch_checkpoints": 3,
       "with_prompt": true,
       "with_parameter_freeze":false,
       "prefix_projection": true
    },
    "data": {
        "directory": "/root/02-ACD-Prompt_v1.0/data",
        "dataset_class": "ACD",
        "text": {
            "train": "train/train-sem.txt",
            "valid": "dev/valid-sem.txt",
            "test": "test/test-sem.txt"
        },
        "label": {
            "train": "train/train_label-sem.txt",
            "valid": "dev/valid_label-sem.txt",
            "test": "test/test_label-sem.txt"
        }
    },
    "model": {
        "name": "ACD_Prefix",
        "model_name_or_path": "/root/02-ACD-Prompt_v1.0/bert-base-uncased",
        "model_save_path":"/root/02-ACD-Prompt_v1.0/ckpt/",
        "pretrained_weights": null,
        "do_lower_case": true,
        "output_attentions": false,
        "output_hidden_states": false,
        "bert_hidden_size": 768,
        "num_class": 8,
        "hidden_dropout_prob": 0.2,
        "hidden_size": 768,
        "prefix_hidden_size": 2,
        "pre_seq_len": 8,
        "num_hidden_layers": 12,
        "num_attention_heads": 12,
        "use_return_dict": false
    },
    "training": {
        "epochs": 100,
        "patience": 5,
        "per_gpu_train_batch_size": 8,
        "per_gpu_eval_batch_size": 8,
        "optim": {
            "learning_rate": 1e-5,
            "max_steps": -1,
            "gradient_accumulation_steps": 1,
            "weight_decay": 0.01,
            "beta_1": 0.9,
            "beta_2": 0.999,
            "adam_epsilon": 1e-8,
            "max_grad_norm": 1.0,
            "warmup_steps": 0
        }
    }
}